
\section{Related Work}

Configuration verification has been considered a promising way  
to tackle misconfiguration problems~\cite{xu15systems}.
Nevertheless, a practical and automatic configuration
verification approach still remains an open problem.

\para{Language-support misconfiguration checking}
There have been several language-support efforts proposed for preventing
configuration errors introduced by fundamental deficiencies in
either untyped or low-level languages. For example, in the network
configuration management area, administrators often
produce configuration errors in their routing configuration files.
PRESTO~\cite{enck07configuration} 
automates the generation of device-native configurations
with configlets in a template language. 
Loo {\em et al.}~\cite{loo05declarative} adopt Datalog to reason about 
routing protocols in a declarative fashion. 
COOLAID~\cite{chen10declarative} constructs
a language to describe domain knowledge about devices and
services for convenient network reasoning and management.
Compared with the above efforts, \app mainly focuses on software systems, 
\eg, MySQL and Apache, and our main purpose is to automate configuration
verification rather than proposing new languages 
to convenient configuration-file writing. 
The closest effort to \app is ConfigC~\cite{santolucitoCAV},
which aims to learn configuration-checking rules from a given training
set. Compared with \app, ConfigC has the following disadvantages.
First, ConfigC requires the configuration files in the training set must 
be correct, which is impractical because it is very difficult to
determine a correct configuration set in reality.
Second, ConfigC covers fewer types of misconfigurations than \app. 
Finally, the training time of ConfigC is much longer than \app.

\para{Misconfiguration detection}
Misconfiguration detection techniques aim at checking configuration
efforts before system outages occur.
Most existing detection approaches check 
the configuration files against a set of predefined correctness 
rules, named constraints, and then report errors if 
the checked configuration files do not satisfy these rules.
Huang {\em et al.}~\cite{huang15confvalley},
for example, proposed a 
language, ConfValley, to validate 
whether given configuration files meet administrators' specifications. 
Different from \app, ConfValley does not
have inherent misconfiguration checking capability, since it only offers
a language representation and requires administrators to
manually write specifications, which is an error-prone
process. On the contrary, \app does not need users to manually
write anything.

Several machine learning-based misconfiguration detection efforts 
also have been proposed~\cite{yuan11context, zhang14encore, xu16early}.
EnCore~\cite{zhang14encore} introduces a template-based
learning approach to improve the accuracy of their learning results.
The learning process is guided by a set of predefined rule templates
that enforce learning to focus on patterns of interest.
In this way, EnCore filters out irrelevant information and reduces
false positives; moreover, the templates are able to express
system environment information that other machine learning
techniques cannot handle.
Compared with EnCore, \app has the following advantages.
First, \app does not rely on any template. 
Second, EnCore cannot detect missing entry errors, type errors,
ordering errors and fine-grained integer correlation errors,
but \app can detect all of them.
Finally, \app is a very automatic system, but
EnCore needs significant human interventions, \eg, system parameters
and templates.

PCheck~\cite{xu16early} aims to add configuration checking code to the system source code by emulating potential commands and behaviors of the system. 
This emulation is a ``white-box'' approach and requires access to the system's source code.
One drawback to this approach is that for some systems (\eg, ZooKeeper) whose behavior is 
hard to emulate, PCheck cannot automatically generate the corresponding checking code.
Due to the emulation based testing strategy, PCheck's scope is limited to reliability problems caused by misconfiguration parameters. 
In contrast, \app is a ``black-box'' approach and only requires a training set of configuration files to learn rules.
By using a rule learning strategy of examples, \app is able to detect general misconfiguration issues that are outside the scope of emulation testing (\eg memory or thread usage settings), including performance, security, availability and reliability.

\para{Misconfiguration diagnosis}
Misconfiguration diagnosis approaches have been proposed to address configuration problems post-mortem.
For example, ConfAid~\cite{attariyan10automating} 
and X-ray~\cite{attariyan12x-ray} use dynamic information
flow tracking to find possible configuration errors that may have resulted in
failures or performance problems. AutoBash~\cite{su07autobash} 
tracks causality and automatically fixes 
misconfigurations. Unlike \app, most misconfiguration
diagnosis efforts aim at finding errors after system
failures occur, which leads to prolonged recovery time.

\para{Association Rule Learning}
The approach we have presented not only generalizes association rule learning, but also another learning strategy called \textit{sequential pattern mining}~\cite{mabroukeh2010taxonomy}. Ordering rules are similar to the patterns learned in sequential pattern mining, although we restrict our ordering rules to $|S|,|T|=1$ since these are the most common misconfigurations we encounter in practice.
While a major limitation to sequential pattern mining is the scalability of the problem~\cite{ayres2002sequential}, we escape this issue with $|S|,|T|=1$ and the fact that a single configuration file tends to be less a few thousand lines.
There has been other work in these same classes of algorithms~\cite{han2007frequent,langley1995applications} for various applications and variations on the core problem.
A future direction for this work is to integrate advances in these domains into the configuration file verification problem.
