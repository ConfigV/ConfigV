
\section{Learning strategy}

A primary concern in any machine learning type task is to minimize both false negatives and false positives.
In the context of configuration file verification,
  a false positive is when \app reports an error on a valid confiuration file and
  a false negative is when \app fails to reports an error on an invalid confiuration file.
Too many false positives will cause users to ignore the reported error\cite{}.
However, since the cost of system failure is so high from a misconfiguration, \app propritzes the minimization of false negatives.

While a traditional classififcation learning machine learning approach can reduce both of these situations, generally, there is can be no garuntee that all false negatives will be eliminated.
Instead of building classification models over the learning set (such as an SVM), we learn the largest set of rules that all correct configuration files satisfy.
In this way, \app can garuntee that, over the set of rules we consider, there will be no false negatives that could have been caught with the given learning set.
The only case of a false negative can be when there was no evidece of such a rule in the learning set - we cannot generate rules from nothing.

$\mathcal{L}$ = Learned Rules\\
$\mathcal{C}$ = Correct Configuration File Learning Set\\
$\mathcal{R}$ = Reported Rules\\
$\mathcal{T}$ = True Rules\\

That is, taking the following definitions:
\begin{flalign*}
\mathcal{T}& =\ \{ r\ \mid \\
  & \forall file \in \mathcal{C},\ r(file)\  \land\\
  & \exists file \in \mathcal{C},\ r(file) \text{ is non-trivial}\ \land \\
  & \text{ if } \neg r(userfile) \text{ then system crash} \} \\
\mathcal{L}& =\ \{ r\ \mid \\
  & \forall file \in \mathcal{C},\ r(file)\  \land\\
  & \exists file \in \mathcal{C},\ r(file) \text{ is non-trivial} \} \\
\mathcal{R}& =\ \{ r\ \mid \\
  & r \in \mathcal{L}\ \land\\
  & \neg r(userfile) \}&\\
\end{flalign*}

We can then conclude that \app is complete but unsound.
The key to showing that \app can be complete lies in proving $\mathcal{R}$ is indeed the set it claims to be.
In order to do this, we must closely examine our implementation.
\begin{flalign}
& \forall r \in \mathcal{T}, r \in \mathcal{R} \qquad \text{[Complete]} \\
& \exists r \in \mathcal{R}, r \notin \mathcal{T} \qquad \text{[Unsound]}
\end{flalign}

The learned rule set, $\mathcal{L}$, is represented as a type, where the type must support a particular interface (called a typeclass in Haskell) to be compatible with our system.
The three methods of this typeclass and the associated specification will help to show completeness of our system.
The functions of this typeclass will be used, invisibly to the user, to make the overall system run.
As long as the specifications for each function are met, \app can garuntee completness.

The typeclass can support anything that is Foldable, which roughly means the user can use any datastructure they prefer.
In fact, in our implementation, two rules are implemented with lists, and two others use hashmaps.

\begin{lstlisting}
class Foldable t => Attribute t a where
  learn :: IRConfigFile -> t a
  merge :: t a -> t a -> t a
  check :: t a -> IRConfigFile -> Error
\end{lstlisting}

\section{Rules}

\subsection{learn}
  For a single given file in the intermediate representation format, learn the full set of rules on that file.
  By overfitting to each file, we can eventually garuntee the completness of \app.
  The specification of this function is the obvious reduction of the Considered Set definition.

  $\text{learn } file =  \{ r | r(file) \land r \text{ is non-trivial}\}$

\subsection{merge}
  Merging the sets of rules from two files to build a new set that is true over both files is the most difficult and important function a rule must implement.
  This is generally implemented as a filter over the union of the two set, but may vary slightly.
  The second predicate of formal specification states that the rule cannot conflict with other existing rules.
  \begin{align*}
  \text{merge }& Set1 \: Set2= \{r \mid \\
    & r \in \text{Set1} \cup \text{Set2}\ \land \\
    & \exists file\ \forall r' \in \text{Set1} \cup \text{Set2}, r(file) \land r'(file) \} \\
  \end{align*}

\subsection{check}
  To check a file by using a rule set, we simply take all the rules that are releveant to the user's file.
  Rules that are relavent are the ones where both parts of the ordering are present.
  We learn the rule set for the user file, and every rule in the learned set must be present in the user file.

% \section{Implementation}
%
% \subsection{System}
% Since we learn a set of rules on each file in isolation from the other, we have an embarrassing parallel situation.
% Haskell allows us to easily take advantage of by using the parallel mapping library, parmap, both for translation to the intermediate representation, and for learning the rules on each file.
%
% \begin{lstlisting}
% learnRules :: [ConfigFile Language] -> RuleSet
% learnRules fs = let
%   fs' = parMap rseq convert fs
%   rs = parMap rdeepseq findAllRules fs'
%  in
%   foldl1 mergeRules rs
% \end{lstlisting}
%
% \subsection{Type Error Rules}
% This builds a map between keywords and types, using the values as evidence.
% see quantum.tex for more
% i will write more on this tomorrow.
%
% \subsection{Integer Relation Rules}
% we only consider the relations , (==), (<=), (>=) because they are easy to pass aroud (as actual functions) in haskell.
% We also committed cardinal since and create an instance for equality over these functions.
% instance Eq (Int->Int->Bool) where
%
% With more engineering effort, this could be extened with the use of a SMT solver to create more fine grained relational rules.
% From our experience, more specific rule are not really needed for integer relations in configuration files.
% However an SMT solver approach would be particularly useful for relations on strings, especially when considering substring relations between filepaths.
%
% \subsection{Ordering and Missing Entry Rules}
% These are the simpiliest of all rules, just making a lot of pairs and seeing which pairs continue to appear over the learning set.
% There is actually a bit of a catch in ordering though - we are not complete over ordering rules.
% This is because only our implementation does not satisfy the specification for the merge function listed above.
% The problem arises from the fact the configuration files may have non-unique keywords.
% Therefor, in the follwoing file we will derive the valid, but conflicting rules ([client],port) and (port,[client]).
% \begin{verbatim}
% [client]
% port = 3306
% [mysqld]
% port = 3306
% \end{verbatim}
% Our implementation of merge removes and conflicting rules for the running set.
% By introducing a renaming pass in the initial parsing we may be able to solve this, but have not found a satisfactory solution yet.

% A core design principle in \app is modularity, so that a user can easily exentend it to their verification needs.
% Rather than try to support every type of verification over configuration files, we provide a framework for defining new verfication properties.
% We call each verification property a rule, for example the correct ordering of keywords or integer relationships between values.
% These rules tend to be pairs of values with a relation.
% For instance, an integer relation rule might be that the value of "foo" must be greater than the value of "bar".
% It is also important that the rule has some empty value, to state that it is known there is no relation between the values.
% This will prevent \app from trying to relearn rules when they have already been refuted.
