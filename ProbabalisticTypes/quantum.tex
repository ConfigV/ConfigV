\section{Quantum Types}

Because our type inference is based on machine learning, we cannot be sure that a keyword unambigously has a single type.
This is an issue when we try to learn relational rules between keywords.
Take the following file in the learning

foo = 300
bar = 300.txt

We want to learn the rule that $foo \in {substring(bar)}$, however using unambigous type inference, we would assign foo type int, and never try to generate a string relation rule for these two keywords.
By assigning foo a quantum type (e.g. ${Int <90\%>, String <10\%>}$), we can now generate rules for both types.

At runtime, when the user wants to check a file we update the probabilities one last time then 'collapse' the quantum type to a concrete type.
If the concrete type collapses to a Int, we consider the rules for ints, and vice versa.

This idea is closely related to exstentially quantified types.

Here is what we know:
- When parsing unstructured (plaintext) data, we may not be given, or able to fully determine, the type of a value.
- We can guess types based on regular expressions over a value.*
- Guessing a concrete type can be overly restrictive. In ConfigC is prematurely pruning the rule search.
- By guessing a set of types with probabilities, we can continously update the distribution, and decide on a concrete type later when we have more information.

Here are things we need to know:
- In ConfigC, we are building probabilistic types, but only operate (i.e. build rules) over the component, concrete types. Can we also operate over probabilistic types and maintain type safety? Fundamentally, we ask "What do we need to add to the simply typed lambda calculus to express probabilistic types?"
- How is this related to existentially quantified types (another "heterogeneous collection" type). Can/should we use this for an implementation?
- How is this related to a value-level probabilistic lambda calculus (where probabilities are on value).
- Does this type system need to be tied to the specific machine learning techniques used in infering types?
- Can we do inference based on more interesting things than just regular expression (something a bit like **, maybe which types generate better rules)
- We might also ask, is there any good reason to operate over probabilistic types? What are other situations when we might need/encounter probabilistic types?

*This focuses mostly on using regular expression to infer concrete types. http://people.csail.mit.edu/rishabh/papers/popl16-semantic.pdf
** http://conf.researchr.org/event/POPL-2016/popl-2016-papers-estimating-types-in-binaries-using-predictive-modeling
