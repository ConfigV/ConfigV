\section{Introduction and System Overview}
\label{sec:Intro}

Configuration errors are one of the most important root-causes of
modern software system failures~\cite{xu15systems,yin11anempirical}.
In practice, misconfiguration problems may result in security
vulnerabilities, application crashes, severe disruptions in software
functionality, and incorrect program executions%
~\cite{xu15systems,zhang14encore,yuan11context}.  Although several
tools have been proposed to automate configuration error diagnosis
after failures occur~\cite{wang04automatic,attariyan10automating,
su07autobash,whitaker04configuration}, these tools rely on manual ways
  to understand and detect the failure symptoms. The main reasons are:
  1) entries in configuration files are untyped assignments, 2) there
  is no explicit structure policy for the entries in configuration
  files, and 3) there is surprisingly little rules specifying the
  entries' constraints.

<<<<<<< HEAD
We propose an approach to the verification of configuration files
which is based on learning rules about the language model for
configuration files.
=======
We propose an approach to the verification of  
configuration files which is based on learning rules about the language 
model for configuration files. \xxx{I think we should explicitly 
mention our approach aims to solve 
misconfiguration from different way with the
previous work. Previous work tries to find out the problem after the
failures occur, but our approach is a proactive method, which can
find out error before the system failure occurs. Such an effort (i.e., 
preventing misconfiguration before installation) is
important, because the majority of errors can be 
detected before running your system. 
Thus, 1) users will not complain too much because they are using
``very healthy'' configuration files, 
and 2) this is a great complementary to existing reactive misconfiguration 
detectors. -- Ennan}
>>>>>>> 613e1c31685d39a5a5f8ba4f513d6b9d639b7345

\begin{figure}[t] \centering
\includegraphics[width=0.8\textwidth]{figs/overview}
\caption{An overview of the \app's workflow.}
\label{fig-overview}
\end{figure}

Fig.~\ref{fig-overview} describes an overview of our system. We start
with an assumption that we are given a number of correct configuration
files belonging to the same category (for instance, MySQL or
Apache). Such files follow the same naming conventions and we use that
fact in a learning algorithm which will result with the rules
describing the language model used in the files. Since the
``language'' of configuration types is untyped and unstructured, we
first parse the files and translate them into a more structured,
typed, intermediary representation. Having more structured files, we
use them as a training set to learn the rules. The learning algorithm
is template-based. We provide an initial set of templates and the
learner learns some concrete instances from the training set. These
rules are used for detecting errors violating the learned constraints
in the files given by the user.

As an 
illustration for a simple rule that we can learn, consider a template is $X_1 \le X_2$, where $X_1$ and $X_2$ are
integer variables. The learned might derive the rule stating that
$\texttt{mysql.max\_persistent} \le \texttt{max\_connections}$. There is a classification and taxonomy of configuration errors in the 
existing work on automated configuration troubleshooting~\cite{yin11anempirical, configdataset}. We provide templates for every class that \app can handle: we consider integer constraints, ordering
constraints, typing constraints, constraints about correlated entries (such as ``if $X$ is present, $Y$ has to appear as well''). Unfortunately, there are a few classes of errors that we cannot handle. They
 rely on the analysis of the whole operating system and our language-based
approach is not expressive enough for them. 

From a  practical perspective there is no additional burden 
to the users: they can simply use \app to check for errors in their configuration files. However, they can also easily extend the framework themselves. The system is designed to be highly modular. If there is a class of rules that \app is not currently learning, the user can develop their own templates and learners for that class. The new learner can be added to \app and this way it can check additionally a new set 
for even more errors.

Second, because many misconfiguration errors have been eliminated 
by \app, the workloads of post-failure forensics in runtime
are significantly reduced, thus making these tools truly practical.
Finally, since there have been many correct but not specific 
example configuration files in practice, 
increasingly more samples can be freely added to \app,
thus giving \app evolutionary capability.

Using these ideas, we make the following contributions:

\begin{enumerate}

  \item Our tool, \app can learn a language model from a set of examples of correct configuration files, and use the model to verify new files.
  \item We present a probabilistic type that can be used to assign a confidence distribution over a set of types to a value.
  \item In \app, we define a minimal interface for describing a verification attribute in a learning context, making it easy to add new rules to the system.

\end{enumerate}
