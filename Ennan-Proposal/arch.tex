
\section{The \app Framework Overview}
\label{sec:overview}

We propose to build \app, an automatic verification framework for 
software configuration files.
In particular, \app is built upon ConfigC and aims at addressing
all the limitations of ConfigC (mentioned in Sec.~\ref{sec:prelim}).
\app is capable of detecting many sophisticated 
configuration errors (\eg, ordering errors, missing entry errors,
and fine-grained value correlation errors) that existing
efforts cannot detect. 
Figure~\ref{fig-overview} presents
a typical \app verification workflow which contains three steps:
translation, learning, and checking. In this section, we briefly
describe how each step works.

\paragraph{Initial phase.}
We start with the assumption 
that we are given a number of (not necessarily correct) 
configuration files, called {\em sample dataset}, 
belonging to the same system (\eg, MySQL or Apache)
as the configuration file we want to verify (called as target
configuration file). Thus, these files (including sample set
and the target configure file) follow similar configuration patterns.
%In the following steps,
%we will exploit in a collection of learning algorithms 
%to build rules that describe a language model for the files.

\paragraph{Translator (Sec.~\ref{sec:lang}).}
The translator module first parses the input sample dataset 
(containing both configuration files and system environment
information), and then transforms them into a more structured
and typed intermediate representation, which follows
our defined language model (see Sec.~\ref{sec:lang} 
for more language model definition details).
When we infer the types of entries in a configuration file, 
the type of an entry cannot always be fully determined from 
a single value, because: 1) it is very hard to understand
the purposes of key-value entries in modern
software configuration files~\cite{xu15hey},
and 2) configuration files in the given sample dataset may contain 
many incorrect entries.
We, therefore, address this problem 
by introducing {\em probabilistic types}.
In particular, rather than giving a variable a single type, 
we assign several types over a probability distribution. 
We can later (in the learner module) use these more structured files
(represented in our defined language model) 
as a training set to determine those probabilistic types, 
thus finally learning the rules. 

\begin{figure*}[tbp] \centering
\includegraphics[width=0.9\textwidth]{figs/overview}
\caption{\app's workflow. The green components represent configuration 
  files, including both sample configuration datasets and users' input
  configuration files to verify. 
  The purple components are the modules of \app.
  Because template DB is not necessarily used, we use dashed
  arrow between it and the learner.
  Red boxes are sub-modules within the checker.
  The yellow components are results generated by \app's modules.}
\label{fig-overview}
\end{figure*}

\paragraph{Learning (Sec.~\ref{sec-learn}).}
The input of the learner is a set of files that have been translated
into well-structured representations (\ie, the translator's
outputs). The learner module employs a collection of learning algorithms
to generate various rules and constraints,
potentially used to handle different types of configuration errors.
These rules and constraints are the outputs of the learner, 
and will be used by the checker to detect errors later.
Because the translator outputs probabilistically typed entries,
the learner is responsible for determining a type for each entry.

\com{Different from previous efforts, \eg, EnCore~\cite{zhang14encore},
which requires users or developers to provide explicit templates,
\app's learner encodes some predefined error-patterns 
to generate rules. 
As an illustration of a simple rule that we can learn,
consider an encoded pattern $X_1 \le X_2$, where $X_1$ and $X_2$ are
integer variables. The learner may derive the rule stating that
$\texttt{mysql.max\_persistent} \le \texttt{max\_connections}$. 
There is a classification and taxonomy of configuration errors in the 
existing work on automated configuration troubleshooting%
~\cite{yin11anempirical, configdataset}. 
Each class can be viewed as an error-pattern 
that \app should handle: we consider integer constraints, 
ordering errors, typing errors, correlation errors, etc.}

\com{
Although the learner has been capable of generating ruldoes not necessarily rely on templates,
\app still offers a database containing many templates,
as shown in Figure~\ref{fig-overview}.
Some of these templates are responsible for offering
specific system executional environment information.
A learning algorithm cannot derive rules 
related to environment violations, \eg,
whether the current account is 
the owner of a certain path, without information 
about the environment. 
In order to deal with comprehensive misconfiguration problems,
the learner needs a template DB to provide environment information,
thus detecting system environment-related configuration errors.}

\paragraph{Checking.}
The checker is used to detect rule violations in the configuration
files of interest. The inputs of the checker are the learned rules,
and the target configuration file to verify.
First, the checker translates the target configuration file into
the representation in our language model, and
then reports whether it has errors by checking it with the
learned rules. 
The checker generates a report (as shown in Sec.~\ref{sec:prelim}) about 
what errors the target configuration file has.
As shown in Figure~\ref{fig-overview},
there are two sub-modules in the checker. They are responsible for
checking rule violations and suspicious values, respectively.
In our experience, we found learned rules could be significantly reused
to check different configuration files, thus improving our usability.  
