% Graph Analysis
% Rahul

\section{Post Analysis}

VeriConf can output the series of learned rules extracted from its training
set as described in $\S$\ref{sec-learn}.

\subsection{Rule Ordering}

\iffalse

Define a graph with labeled, weighted edges $G = (V,E)$ such that:

    V \def { keywords }

Where 

    E \def { (v_1, v_2, l, w) }

Where the label $l$ defines the relationship, and the weight $w$ is
defined as $w = \frac{true - false}{total}$ for that relationship.
Note that due to support / confidence assertions in the learner, we
may be assured that all weights in the graph are positive.

Structure:
    - Definition
        > Degree (in-degree + out-degree) for each node 

        Define in-degree and out-degree in the usual way:

            IN_DEGREE(k) = ||

            \forall keyword k \in rules, in_degree()

        Note that we will be summing in-degree and out-degree over all
        relationships $l$ to determine the total importance of
        a keyword $k$ in the configuration space. We are restricted
        by the total set of learning modules from which to derive
        relationships $l$. If a keyword were highly constrained by some
        relationship to other keywords in a way that might not be
        measurable by current techniques, the learner (and therefore
        consequently the graph) will show these keywords as being
        unrelated.

    - Semantics
        > Intuitively, keywords that are seen together more often
          with defined relationships
          are more likely to generate rules within the learner.
          (it would be nice to show this with a quick derivation)

          for a rule to be considered *true*, two conditions must hold:

            - adequate support
                we have seen the keywords together x number of times

            - adequate confidence
                how many times out of the x number of times 
                was the relationship true?

    - Open Questions
        > What is the difference between {\it important} rules and
          {\it rules we are more sure about}?

        > Why doesn't everything just sum to zero?

\subsection{Complexity Measure}

INCLUDE SHORT BACKGROUND ON CODE COMPLEXITY. We define a measurement
of complexity based on the calculated correlation. The presented
metric is a heuristic that intends to approximate the quetion, 
{\it how much redundancy exists in a configuration file, when considering
probabilistic constraints imposed by the problem domain}?

it may be possible in the future to have interpreted predicates,
such that these heuristics may more accurately reflect the informational
content of a constrained configuration file.

\fi




