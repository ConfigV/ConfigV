\section{Learning the Rules}
\label{sec:system}

To learn rules, we first translate to the intermediate representation where each line of a configuration file is reduced to a keyword-value pair $(k,v)$.
Parsing is language dependent and users may provide extra help to the translator for their specific language, such as specifying a comment character.
We must assign types to the keywords to guide the learning modules. 
With typed keyword-value pairs, we can run each learning module independent of each other.
We learn a set of rules over every file, then merge them.

\para{Introducing the types.} 
Based only on a single example value of $v$ we cannot fully determine the type of $k$.
Consider for instance the following example:\\
\texttt{\hspace*{2em}foo = 300\\
\hspace*{2em}bar = 300.txt}\\
Most likely \texttt{foo} is an integer and we learn an equality rule, but it could also be a string.
In this case we want to learn the rule $ \texttt{foo} \in \textsf{substrings}(\texttt{bar})$. 
We therefore assign a distribution of types to a value, an idea closely related to existentially quantified types \cite{Launchbury93lazyfunctional}. We introduce {\emph{probabilistic types}} to address this issue.

Let $\mathcal{T}$ be a set of basic types. In \app set $\mathcal{T}$ contains strings, integers, file paths, sizes and IP addresses. 
A probabilistic type built from $\mathcal{T}$ is a list of pairs $[(\tau_1, p_1),\ldots,(\tau_n, p_n)]$ such that $\tau_i \in \mathcal{T}$, 
$0 \le p_i \le 1$ 
and $\Sigma p_i = 1$. These probabilities are updated each time a new example value for a keyword is encountered.

When a value has a probabilistic type, we generate rules for all its types. This means that by assigning {\texttt{foo}} a probabilistic type 
(e.g. $(\texttt{foo}, 300, [(\textsl{Int},90\%),(\textsl{String},10\%)])$
we now generate rules for both strings and integers.
Once the type inference can uniquely determine the type, the probability of all other types is set to zero, and the associated rules are withdrawn.

Note that typing is also a system module than can be easily extended to support more types. 
In that case the user will need to provide rules for type inference and probability distributions for values where type inference is ambiguous.

\para{Rule Learning.} 
With every type we associate a set of templates, specific to this type. Once the input files are fully type-annotated, we generate rules that are instances of these templates. We always learn the largest set of rules that all correct configuration files satisfy. This way \app can guarantee that, over the set of rules we consider, there will be no false negatives that could have been caught with the given learning set. The only case of a false negative can be when there was no evidence of such a rule in the learning set - we cannot generate rules from nothing. 
%Framed as the question "Is this file valid", \app is complete but not sound
