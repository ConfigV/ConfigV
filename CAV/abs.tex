
\begin{abstract}

Software failures resulting from configuration errors 
have become commonplace as modern software systems 
grow increasingly large and more complex.
The lack of language constructs in configuration files, 
such as types and grammars, 
has directed the focus of a configuration file verification 
towards building post-failure error diagnosis tools. 
In addition, the existing tools are generally language
specific, requiring the user to define at least a grammar for the language
models and explicit rules to check. 
In this paper, we propose a framework which analyzes
datasets of correct configuration files and derives rules for building a
language model from the given dataset. 
The resulting language model can be used
to verify new configuration files and detect errors in them. 
Our proposed framework is highly modular, 
does not rely on the system source code, and
can be applied to any new configuration file type with minimal user input.  
Our tool, named \app, relies on an abstract representation of language 
rules to allow for this modularity. 
\app supports learning of various rules, such as orderings,
value relations, type errors, or user defined rules
by using a probabilistic type inference strategy and
defining a small interface for the rule type.

\end{abstract}
