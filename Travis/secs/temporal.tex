\section{Learning from Temporal properties}

%The first step is to build an intermediate representation of the data we will learn.
%This data must be structured as a shallow tree for generalizable learning.
%This restriction is why this approach is not appropriate for language learning on large grammars (such as a programming language).

In ConfigC, the configuration files were analyzed as standalone documents.
Since a TravisCI configuration file is dependent on the code it is trying to build, we must consider a more general sense of configuration file.
We will call this a program summary $P_t$, which is a representation of the repository which contains the information relevant to the learning process.
In the case of TravisCI, this include the \verb|.travis.yml| file, as well as extract key code features that may effect build status, such as programming language and a list of imported libraries.
The summary must contain every piece of information that might lead to a build error.

The subscript on $P_t$ is a time stamp tag based on the ordered commit history.
However, a git history is not a limited to a single linear timeline.
Git features the ability to \textit{branch}, which allows to simultaneous commit chains.
To handle the start of a branch, add a superscript to indicate the branch, and restart the counter on a branch.
To handle the merge of two branches $P_{t}^{x}$ and $P_{t'}^{y}$, step to $P_{t+1}^{x}$, where $x$ is the mainline branch.
We then say that $P_{t'}^{y}$ has no successor commit $P_{t'+1}^{y}$.

We will denote the build status of $P_t$ with $S(P_t)$.
In this application, we consider only the passing and erroring build status, denoted $Pass$, and $Err$ respectively.
All status that are not \verb|error|, as defined by the Travis API, will be included as passing.
For brevity, we denote sequences of build statuses with the following notation:

\begin{align*}
  S(P_t)=Pass \land S(P_{t+1})=Err \implies S(P_{t,t+1}) = PE
\end{align*}

From this summary we can then build a model $M(P_t)$, as in ConfigC, which is the full set of possible relations derivable from the program summary.
In contrast with ConfigC, we now consider both positive and negative examples and so must introduce the \textit{general boundary}.
The general boundary is the dual of the specific boundary, and is the most relaxed requirement for a positive classification.
We denoted specific boundary as the set of necessary relations $Nec$, and now denote the general boundary as the set of breaking relations $Br$.
With this notation, we can formally express the requirement that the program summary is complete.

\begin{align}
  \forall S(P_t)=Err, \exists r \in M(P_t), r \in Br \label{eq:E1}
\end{align}

From the above we know that if a build is erroring, then there must exist at least one error.
By pushing the negation into the formula, we can also know that if a build is passing, then there must not exist any errors.
That is, the model of a passing commit must not contain any rules which are breaking.
Note we are not, however, guaranteed that any rules from a passing commit are necessary.


\begin{align}
  S(P_t) = Err \implies \exists r \in  M (P_t), r \in Br \label{eq:E}\\
  S(P_t) = Pass \implies \forall r \in  M (P_t), r \notin Br \label{eq:P}
\end{align}

While Eq. \ref{eq:E} and \ref{eq:P} might build a basic model, they will do not capture all of the available knowledge.
The key insight is that when we commit a break (P E), we can localize the error to one of the lines that changed.
Either we removed something that was necessary, or added something that was breaking.
We use an inclusive disjunction, since a erroring commit can break multiple things at once.
Expressed formally, where $\setminus$ is the set difference, that is:


\begin{align}
  S(P_{t,t+1}) = PE \implies \nonumber \\
  \exists r \in (M(P_{t})\ \setminus M(P_{t+1})), r \in Nec\ \lor \nonumber \\
  \exists r \in (M(P_{t+1}) \setminus M(P_{t})), r \in Br \label{eq:PE}
\end{align}

We then can combine all these formulas with conjunctions and send it to an SMT solver.
While existential set operations can be expensive on large sets for an SMT solver, in our application this is not the case.
Thanks to the practice of making incremental commits when using source control, these sets will be small and the SMT will be fairly cheap.
In fact, the above implication generalizes to $P_{t,t+n}$, but for efficiency we must require that $M(P_{t})\ \setminus M(P_{t+n})$ is manageably small.
The definition of small here remains to be experimentally determined.
