\section{Learner}
\label{sec-learn}


The goal of the learner module is to derive rules and constraints from
the intermediate representation generated by the translator.
In general, the learner module has two components.
The first component ($\S$\ref{subsec-rules}) 
learns rules for checking configuration errors like
entry missing, ordering errors, and fine-grained value correlation errors. 
These errors tend to cause total system failures.
%Once the configuration file has been validated against such rules, 
%the user may choose to invoke a more sensitive constraint checker. 
The second component ($\S$\ref{subsec-constraints}) 
aims to derive 
constraints on entries to check for suspicious (or anomalous) values 
that may violate standard practice. These anomalies can cause partial 
degradation of the system, 
such as significant reduction in performance, or even 
total failure as in Example~4 of $\S$\ref{sec-motiv}.

\subsection{Derivation of Probabilistic Rules}
\label{subsec-rules}

The first component learns rules 
that must hold over multiple parts of a configuration file.

\para{A strawman solution.}
We first present a strawman solution (employed by
previous work~\cite{santolucitoCAV, zhang14encore}) that uses 
a set of correct configuration files as a learning set, 
from which it is possible to derive rules 
that must hold with absolute certainty. 
In practice, however, it is difficult to obtain a set of files 
that is both guaranteed to be without misconfiguration 
and large enough to learn many rules of configuration files.
This usually requires manual verification of the learning set, 
which is prone to error.

As a result of this restriction, 
these efforts only consider a rule if it holds over exactly every file in 
the learning set. This behavior can be formally described as follows:
\begin{small}
\begin{align*}
C :=&\ \text{Correct Learning Set}\\
LR :=&\ \text{Learned Rules} :: \{\textrm{Rule}\}\\
RR :=&\ \text{Reported Rules} :: \{\textrm{Rule}\}\\ 
C =&\ \text{\{Configuration Files in Intermediate Representation\}}\\
LR =&\ \{ r\ \mid \forall file \in C,\ holds(r,file)\} \\
RR =&\ \{ r\ \mid r \in LR \ \land \neg\ holds(r,\textrm{user file}) \}\\
\end{align*}
\end{small}
In the above, the ":: \{Rule\}" notation indicates that the $LR$ learned rules 
and $RR$ reported rules are sets of rules.
A rule is only committed to the $LR$ learned rule set if 
the rule holds on all files in the training set $C$, as denoted by the $\forall$ quantifier. 
A broken rule is reported to the user in the $RR$ rule set if the rule is in $LR$, 
but does not hold on the input user file.

Each rule can be viewed as a mapping from 
attributes $a_j$ and $a_k$ in the intermediate representation of a 
configuration file to a boolean function, $R$: this can be represented by a rule
$r := (a_j, a_k) \rightarrow B_{rel}$.
$B_{rel}$ is a Boolean function specific to the relation to assess, meaning that 
the desired relation can either be satisfied or not satisfied. 
For instance, for the rule that {\tt max\_connections} must 
be greater than {\tt mysql.max\_persistent}, the relation of interest is $>$ 
and $B_{>}$ would be set to true.

\para{Our approach.}
In \app's learner module, the rule learning mechanism is tolerant 
enough to accept a dataset {\em full of} incorrect configuration files.
Rather than manually correcting each file, 
we extend the previous formalism to run probabilistic learning
on our intermediate representations (generated by the translator). 

\begin{algorithm}
\caption{Probabilistically Learn Rules}
  Let $\theta$ be the list of possible types for the intermediate representation of interest.
  \begin{algorithmic}[1]
  \State \textbf{learnRules}($C$):\\

  Input: set $C$ contains intermediate representations\\ 
     \qquad \enspace \enspace of configuration files\\

    \State $R = \{\}$ // denotes rule set
    \State $P$ // denotes probabilities associated with rule set
    \For{each file $F$ in $C$}
      \For{each $\tau \in \theta$}
        \State $Q = filter(F,\tau)$ 
        \State // $Q$ contains entries in $F$ with $\tau$ in type list
        \State $RM$ contains entries in remove set
        \For{each entry $e$ in $Q$}
               \If{$g(e)$ is false}
                        \State continue to next entry
                        \Else \enspace $CR = \textrm{constructRules}(e, \tau, Q \backslash RM)$
                        \State $R = R  \cup CR$
                        \State For each $r \in CR$, update $P$ 
               \EndIf
               \State $RM = RM \cup e$
        \EndFor
     \EndFor
    \EndFor
    \State Based on $P$, accept rules in $R$ according to threshold. 
  \end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{constructRules}
  \begin{algorithmic}[1]
  \State \textbf{constructRules}($e, \tau, S$):\\
    Input: entry $e$ from intermediate representation\\ 
     \qquad \enspace \enspace type $\tau$\\
     \qquad \enspace \enspace set of entries $S$\\
     $R = \{\}$
     \For{each $t \in templates(\tau)$}
        \State Let $n$ be the arity of $t$
        \State Let $P$ be the set of permutations of distinct entries from $S$, of size $n-1$. 
        \For{each $p \in P$}
         \State Let $p$ be represented by $(e_1, e_2, \ldots, e_{n-1})$.
           \For{$i = 1:n$}
           \State Create a $n$-tuple by placing $e$ at the $i$-th place and filling the remaining entries with $p$, in order. Let this $n$-tuple be $u = (e_1, e_2, \ldots, e_i, \ldots, e_{n-1})$.
           \State $r = \textrm{constructRule}(u)$ 
            \If{$r$ is satisfied}
              $R = R \cup r$
            \EndIf
          \EndFor
        \EndFor
     \EndFor
     \State return $R$
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{constructRule}
  \begin{algorithmic}[1]
  \State \textbf{constructRule}($u$):\\
  Input: a tuple of entries, $u$, denoted by $(e_1, e_2, \ldots, e_i, \ldots, e_{n-1})$ \\
    \State return $t(k(e_1), k(e_2), \ldots, k(e_i), \ldots, k(e_{n-1}))$.
  \end{algorithmic}
\end{algorithm}

%each entry is listed as (g,k,v,typelist)

Our probabilistic approaches for learning the entry missing, 
ordering, and fine-grained value correlation rules stem 
from existing work with building 
the non-probabilistic versions of these rule-learning algorithms. 
We start with the idea that for each of these rules, 
we are going to consider all possible pairs of keys that appear in every 
file, and for our learning process, calculate the likelihood that each of 
these pairs constitute a rule. 
In essence, this is a mechanism that will consider many different possible 
pairs of lines of entries in the file, 
and attempt to compile a set of these pairs 
that are expressed more often than others as a basis for finding patterns 
within the example set that can be used to evaluate new files.

More formally, this approach can be defined as follows. 
The output of our learning algorithm is augmented to a map from 
key-value pairs to a probability distribution over number of possible 
relations.

\[
\{ P\_Rule = (a_j, a_k) | j \neq k \} \rightarrow \{ (R_1, R_2, ... , R_n) \}
\]

We can think of each of these $(a_j, a_k)$ as possibly having a different relationship, defined by the set $\{ R_i \}$, which cover the entire outcome space of possible relationships between the two values $(a_j, a_k)$.

For the entry missing rules, we define $R_1$ as the event that $a_j$ and
$a_k$ appear together, and $R_2$ to be the event that $a_j$ appears
without $a_k$, or by the transitive equivalent, $a_k$ appears without
$a_j$. For the ordering rules, we define $R_1$ as the event that
$a_j$ appears before $a_k$ and $R_2$ be the event that $a_k$ appears
before $a_j$. For the value correlation rules, we define $R_1$ as the
event that $a_j \leq a_k$, $R_2$ the event that $a_j = a_k$, and $R_3$
the case that $a_j \geq a_k$. Notice that the $R_i$ do not have to be
disjoint, but only have to union to the entire probability space.

By examining the learning set, we will derive a distribution of the set $\{R_i\}$ based on how many times we observe an occurrence of each relation. This distribution will then be used at checking time to determine if a user's configuration has broken a likely rule. 

\begin{small}
\begin{flalign*}
I\ \ =&\ \text{Incorrect Learning Set}\\
\text{::}\ & \text{\{Configuration Files in Intermediate Representation\}}\\
LP =&\ \text{Learned Probabilistic Rules :: \{P\_Rule\}}\\
RP =&\ \text{Reported Probabilistic Rules :: \{P\_Rule\}}\\
LP =&\ \text{count\_relation\_occurrences}(I)\\
RP =&\ \{ r\ \mid r \in LP\ \land \Pi(r)>p \land \neg r(userfile) \}
\end{flalign*}
\end{small}

A rule will be reported as broken if the probability the rule is
correct, $\Pi$, is greater than some user defined constant, $p$. This
constant can be adjust to the user's preference. A small $p$ will
increase the likelihood of finding an error, but also increase the
number of false positives that are reported.

\ennan{So far, it is still not clear what does 
our claimed language model look like?}


\subsection{Learning Suspicious Constraints}
\label{subsec-constraints}

With a configuration file that has been verified against catastrophic
failures (\eg, entry missing, type and ordering errors), 
the user may also want to find out more subtle issues.
Anomalous values can cause tricky, but impactful, performance and memory
issues that are hard to debug, as discussed in Example 4 of 
$\S$\ref{sec-motiv}. 
Consequently, anomalous values should be flagged and a warning returned
to the user indicating the violation.

We now describe the technique we use to detect anomalous values for 
numerical attributes. Let $A$ be the set of attributes contained in the 
configuration files in the sample dataset. 
Let $A_n$ be the subset of attributes of $A$ which are numerically typed. 
Then, for each attribute $a \in A_n$, we construct a vector $v_a$ of the 
values corresponding to attribute $a$, seen over the entire sample dataset.
For each $v_a$, we compute 
an interval  $$[\hat{v_a} - 50*MAD(v_a), \hat{v_a} + 50*MAD(v_a)],$$ 
where $\hat{v_a}$ represents the median over the values 
in $v_a$ and $MAD(v_a$) refers to the 
median absolute deviation. 
This is a variant of a standard outlier detection test, namely the Hampel identifier.\footnote{Mathematically, $MAD(v_a) = 1.4826* median(|v_a - \hat{v_a}|)$, estimating standard deviation 
for a normal distribution.} 
In the checking phase, as long as the checker finds a value for a numerical 
attribute in the checked file outside of this interval, 
a warning would be printed to the user indicating the violating value, 
the attribute, and the upper or lower Hampel threshold. 

The intuition behind this is that if the user has input a value 
that falls outside of an interval containing values that are considered 
``normal'' over the entire sample dataset, 
that value will probably cause an error, in particular for performance. 
We cannot know for sure if this value will cause an issue. 
For instance, a user might have a machine with 
particularly high-end hardware, 
in which case a value beyond the upper Hampel threshold may be appropriate. 
