
\section{Learner}
\label{sec-learn}

\ennan{This section details how do we extract rules from the
intermediate representations. This section may should have the following
two subsections: Aaron's part (including Xinyu's fine-grained
value correlation rule learning) and Jonathon's part.
In addition, we may need to add one more subsection about
learning system environment information related rules,
\eg, for paths and users.}
\markk{I am not sure how much space we have to discuss the details of each learning module, or how important that is here. I have only discussed the overall architecture of probabilistic learning, and it already takes quite a bit of space. maybe module specific stuff should go into sec 8 (implementation)? please advise.}

In general, the learner module has two parts of learning tasks.
The first is to learn rules in order to check configuration errors like
missing entry, ordering errors, and correlation errors. These are the types of errors that tend to cause total system failures.
Once the configuration file as been validated against such rules, the user may choose to invoke a more sensitive constraint checker. This second step learns constraints on singular entries to check for suspicious (i.e. anomalous) values that may violate standard practice.

\subsection{Derivation of probabilistic rules}
\label{subsec-rules}

\para{Learning from an incorrect set.}
The first step of \app is to learn relations that must hold over multiple parts of a configuration file.
Previous work used a set of correct configuration files as a learning set, from which it was possible to derive rules that must hold with absolute certainty\cite{santolucitoCAV}. 
However, this is approach is severely limiting. 
It is difficult to obtain a set of files that is both guaranteed to be without misconfiguration and large enough to learn the many rules of configuration files.
This usually requires manual verification of the learning set, which is prone to error.

As a result of this restriction, the tool introduced in \cite{santolucitoCAV} will only consider a rule if it holds over exactly every file in the learning set. This behavior can be formally described as follows:

\begin{flalign*}
C =&\ \text{Correct Learning Set}\\
\text{::}\ & \text{\{Configuration Files in Intermediate Representation\}}\\
LR =&\ \text{Learned Rules :: \{Rule\}}\\
RR =&\ \text{Reported Rules :: \{Rule\}}\\
&\\
LR =&\ \{ r\ \mid \forall file \in C,\ holds(r,file)\} \\
RR =&\ \{ r\ \mid r \in L\ \land \neg\ holds(r,userfile) \}&\\
\end{flalign*}

Each rule can be thought of as a mapping from lines j and k in a configuration file to a relation, $R$.

\[
\{ Rule = (a_j, a_k) | j \neq k \} \rightarrow \{ R \}
\]

Specifically, $a_j$ and $a_k$ are two different lines from our intermediate representation, or more formally, $j \neq k \land \vee a_j, a_k \in \{ L \})$ where  is the set of lines (keyword-value pairs) found in the intermediate representation of our learning set. The relation $R$ is a Boolean function specific to the error we wish to detect. As an example, to detect the error that keyword k1 must always have a value greater than keyword k2, the relation $R$ is $>$.

In \app, the rule learning mechanism is tolerant enough to accept a database of incorrect configuration files.
Rather than manually correcting each file, we observe that the files are usually incorrect in only one or two lines.
We then extend the previous formalism to handle probabilistic learning, when we have a collection of such files.

Our probabilistic approaches for learning the Missing Values, Keyword Ordering, and Integer Relations rules stem from our previous work with building the non-probabilistic versions of these rule-learning algorithms. We start with the idea that for each of these rules, we are going to consider all possible pairs of keywords that appear in every file, and for our learning process, calculate the likelihood that each of these pairs constitute a rule. In essence, this is a mechanism that will consider many different possible pairs of lines in the file, and attempt to compile a set of these pairs that are expressed more often than others as a basis for finding patterns within the example set that can be used to evaluate new files.

More formally, this approach can be defined as follows. The output of our learning algorithm is augmented to a map from keyword-value pairs to a probability distribution over number of possible relations.

\[
\{ P\_Rule = (a_j, a_k) | j \neq k \} \rightarrow \{ (R_1, R_2, ... , R_n) \}
\]

We can think of each of these $(a_j, a_k)$ as possibly having a different relationship, defined by the set $\{ R_i \}$, which cover the entire outcome space of possible relationships between the two values $(a_j, a_k)$.

For the missing keywords rules, we define $R_1$ as the event that $a_j$ and $a_k$ appear together, and $R_2$ to be the event that $a_j$ appears without $a_k$, or by the transitive equivalent, $a_k$ appears without $a_j$. For the keyword ordering rules, we define $R_1$ as the event that $a_j$ appears before $a_k$ and $R_2$ be the event that $a_k$ appears before $a_j$. For the integer relations rule, we define $R_1$ as the event that $a_j \leq a_k$, $R_2$ the event that $a_j = a_k$, and $R_3$ the case that $a_j \geq a_k$. Notice that the $R_i$ do not have to be disjoint, but only have to union to the entire probability space.

By examining the learning set, we will derive a distribution of the set $\{R_i\}$ based on how many times we observe an occurrence of each relation. This distribution will then be used at checking time to determine if a user's configuration has broken a likely rule. 

\begin{flalign*}
I\ \ =&\ \text{Incorrect Learning Set}\\
\text{::}\ & \text{\{Configuration Files in Intermediate Representation\}}\\
LP =&\ \text{Learned Probabilistic Rules :: \{(P\_Rule)\}}\\
RP =&\ \text{Reported Probabilistic Rules :: \{(P\_Rule)\}}\\
&\\
LP =&\ \text{count\_relation\_occurrences}(I)\\
RP =&\ \{ r\ \mid r \in LP\ \land \Pi(r)>p \land \neg r(userfile) \}&\\
\end{flalign*}

A rule will be reported as broken if the probability the rule is correct, $\Pi$, is greater than some user defined constant, $p$. This constant can be adjust to the user's preference. A small $p$ will increase the likelihood of finding an error, but also increase the number of false positives that are reported.


\subsection{Learning Suspicious Constraints}
\label{subsec-constraints}
With a configuration file that has been verified against catastrophic failures, the user may also use \app to find more subtle issues. Anomalous values can cause tricky, but impactful, performance and memory issues that are hard to debug, as discussed in Example 4 of Section \ref{sec-motiv}. 
Consequently, suspicious values should be flagged and a warning returned to the user indicating the violation.

We now describe the technique we use to detect anomalous values for 
numerical attributes. Let $A$ be the set of attributes contained in the 
configuration files in the sample dataset. 
Let $A_n$ be the subset of attributes of $A$ which are numerically typed. 
Then, for each attribute $a \in A_n$, we construct a vector $v_a$ of the 
values corresponding to attribute $a$, seen over the entire sample dataset.
For each $v_a$, we compute 
an interval  $$[\hat{v_a} - 50*MAD(v_a), \hat{v_a} + 50*MAD(v_a)],$$ 
where $\hat{v_a}$ represents the median over the values 
in $v_a$ and $MAD(v_a$) refers to the 
median absolute deviation. 
This is a variant of a standard outlier detection test, namely the Hampel identifier.\footnote{Mathematically, $MAD(v_a) = 1.4826* median(|v_a - \hat{v_a}|)$, estimating standard deviation 
for a normal distribution.} 
In the checking phase, as long as the checker finds a value for a numerical 
attribute in the checked file outside of this interval, 
a warning would be printed to the user indicating the violating value, 
the attribute, and the upper or lower Hampel threshold. 

The intuition behind this is that if the user has input a value 
that falls outside of an interval containing values that are considered 
``normal'' over the entire sample dataset, 
that value will probably cause an error, in particular for performance. 
We cannot know for sure if this value will cause an issue. 
For instance, a user might have a machine with 
particularly high-end hardware, 
in which case a value beyond the upper Hampel threshold may be appropriate. 
