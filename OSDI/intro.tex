\section{Introduction}
\label{sec-intro}

Configuration errors are one of the most important root causes of
today's software system failures~\cite{xu15systems, yin11anempirical}.
For example, Yin {\em et al.}~\cite{yin11anempirical} reveal
that about 31\% system failures were caused by misconfiguration problems. 
Misconfigurations, in practice, may result in various
system-wide problems, such as security vulnerabilities, 
application crashes, severe disruptions in software
functionality, and incorrect program executions%
~\cite{zhang14encore, yuan11context, xu13do, xu15hey}.  

While many efforts have been proposed 
to check, troubleshoot, diagnose and repair configuration errors%
~\cite{attariyan10automating,
su07autobash, whitaker04configuration}, 
offering automatic verification to configuration files -- like what we
did for verifying regular programs -- is still highly
desirable~\cite{wang04automatic, zhang14encore, xu15systems}.
Nevertheless, the main obstacles to the configuration verification are:
1) entries in configuration files are untyped entries, 2) there
is no explicit structure policy for the entries in configuration
files, and 3) there are surprisingly few rules specifying the
entries' constraints.

In order to overcome these obstacles,
researchers propose statistical analysis and learning based approaches%
~\cite{wang04automatic, zhang14encore, yuan11context}. 
These efforts build checking policies by learning a sample 
data set, rather than explicitly specifying entries' types or rules.
In particular, for each entry in a certain configuration file, 
if it deviates from the common values used in a large collection
of configurations (\ie, the training data set), it is typically
suspected as a potential configuration error.
However, because these learning 
efforts {\em either} are limited to simplistic 
configuration errors (\eg, type errors and syntax errors), 
{\em or} heavily rely on template-based inference~\cite{zhang14encore}, 
many sophisticated configuration errors, 
\eg, hard to be templated in practice, cannot be detected.
For example, if {\tt extension = mysql.so} appears 
before {\tt extension = recode.so} in PHP configuration file,  
it would lead to a crash error, since the correct ordering 
should be {\tt extension = recode.so} before 
{\tt extension = mysql.so}~\cite{yin11anempirical};
however, such an error cannot be detected by existing
learning efforts, since it is hard to build a template for this
error~\cite{xu15systems}.

%Offering automatic verification to configuration files -- like
%what we did to programs -- has been advocated as a reasonable means
%to check the correctness of configuration files of interest.
%Nevertheless, it is still an open problem, because 
%1) software configurations are typically written in poorly structured 
%and untyped languages, and 2) writing specifications or constraints
%for configuration verification is non-trivial in practice.

In order to truly achieve automatic configuration verification,
we argue that we need to leverage a collection of more powerful learning 
algorithms (not necessarily depending on templates) to derive 
a more sophisticated language model (with abundant rules covering
tricky configuration errors), and then check the configuration files
of interest through the learned language model.

Based on the above argument, 
this paper presents \app, the first automatic verification framework
for general software configurations.
In particular, \app's workflow to verifying a given configuration file
could be looked as a three-step methodology.
First, \app analyzes a dataset containing sample configuration files,
thus generating a well-structured and probabilistically-typed 
intermediate representation.
Second, \app derives rules and constraints by analyzing
the intermediate representations, thus building a language model.
Finally, \app uses the resulting language model
to verify the given configuration file and detect potential errors.
Compared with previous efforts,
\app does not necessarily rely on users' templates, 
and is capable of detecting more tricky configuration errors that
cannot be identified by existing work (details in $\S$\ref{sec-motiv}). 

Building such an automatic verification framework for
configuration files, nevertheless, requires addressing several challenges. 
First, in order to formulate a correct language model, 
we need to infer each entry's type in a given configuration file;
however, the type of a variable cannot always be fully determined 
from a single value. 
For example, an entry {\tt foo = MAX\_SIZE} is most likely
an integer rather than string; however, existing type inference 
work would report this is an error, because foo should be assigned
an integer~\cite{zhang14encore}. We address this problem by introducing 
so called {\emph{probabilistic types}}.
Rather than assigning only one variable to a single type, 
we assign several types with their probability distributions. 
The entry in the above example might be assigned 
a probabilistic type like 
{\tt \{foo, MAX\_SIZE, [(Int, 60\%), (String, 40\%)]\}}.
With such probabilistic types in hand,
we can generate a more accurate language model,
thus significantly improving our checking capability.

Second, without template, how to learn rules and constraints present
a difficult. \ennan{Here, we need to add one-paragraph description 
to illustrate how we learn rules without templates.}

\com{First, given the fact that 
different systems' configuration files use various representations, 
the cost of introducing a completely new configuration
language (or representation) to instead of all these existing format looks 
like an impractical goal. This is not only because administrators need 
to learn this new language, but also changes existing system
infrastructure to support such a new language. 
In order to avoid the above issues, we propose a representation,
which is a type-based representation and 
much more structured than existing configuration format, 
but use it as an intermediate layer. We, at the same time,
develop many pluggable parsers
that can transform different systems' configuration representations
into our proposed intermediate representation for the post process.}

From a practical perspective, 
\app introduces no additional burden 
to the users: they can simply use \app to check for errors in their
configuration files. However, they can also easily extend the framework
themselves. The system is designed to be highly modular. If there is a
class of rules that \app is not currently learning, the user can develop
their own templates and learners for that class. The new learner can be
added to \app and this way it can check additionally a new set of
errors.

Our \app prototype still has a few limitations,
\eg, cannot handle errors occurred in execution time.
Nevertheless, we believe \app may suggest a practical path
toward automatic and language-based configuration verification.
To summarize, this tool paper makes the following contributions:

\com{
Finally, from a systems perspective this is the first approach that {\emph{proactively}} checks 
 the correctness of configuration files. All previous work
~\cite{xu15systems,zhang14encore,yuan11context, wang04automatic,attariyan10automating,
su07autobash,whitaker04configuration} tries to identify the problem after the
failure occurred. Our approach isolates potential errors before the system failure occurs, e.g. before the installation. We can also see \app as a tool that can run in conjunction with existing tools. Pre-analyzed configuration files are already free from language-based errors, and this way the workloads of post-failure forensics at the runtime
is significantly reduced, thus making these tools truly practical.
}


\begin{enumerate}

\item We propose the first automatic configuration verification
framework, \app, that can learn a language model from an example set of 
correct configuration files, and then uses this language model to verify 
interested configuration files.
 
\item \app proposes probabilistic types to assign a confidence 
distribution over a set of types to each entry, 
while generating the intermediate representation. 

\item \app employs a collection of machine learning algorithms to 
enable powerful rule and constraint inference without the assistance 
from any pre-defined templates.

\item \app is capable of detecting various tricky errors that cannot
be detected by previous efforts,
including ordering errors, fine-grained value correlation errors, 
entry missing errors, and environment related errors. 

\item We implement a \app prototype and evaluate it by
conducting comprehensive experiments.

\end{enumerate}
