
\section{Implementation}

\ennan{We need to describe how do we implement each module. We may need to
have three paragraphs: one is for translator, one is for learner 
and one is for checker.}

\section{Evaluations}

We mainly conduct three parts of experiments to evaluate our \app
prototype. We want to answer several questions:

\begin{itemize}

\item Whether \app can detect real-world configuration errors?

\item How does the size of training dataset impact on the correctness
  of \app?

\item What is the rule inference accuracy?

\item How long can we run the verification?

\end{itemize}

\subsection{\app's effectiveness}

In order to evaluate the effectiveness of \app, we extract
20 misconfiguration files from a MySQL dataset~\cite{xu15hey},
and perform \app on them. \ennan{Here, we first need a table to 
list each configuration error with error type, description,
and whether \app correctly reports the issues.}

\begin{table*}[t]
\centering
\caption{Sampled benchmarks for misconfiguration detection}
\label{table-casestudy}
\begin{tabular}{|l|l|l|l|}
\hline
{\bf ID} & {\bf Problem Description} & {\bf Error Type} & 
{\bf \app Report}  \\ 
\hline
\hline
1 & How to configure MySql master slave to  
& Type Error 
& Expected a Filepath with P=1.0 \\ & backup master to slave & 
& for log-bin[mysqld] \\ \hline

2 & data import from MySql dies when MySQL  
& Correlation 
& Expected thread\_cache\_size[mysqld] > \\ & query limit is removed 
& & innodb\_buffer\_pool\_size \\ \hline

\end{tabular}
\end{table*}

Next, we inject some errors to correct configuration files,
and run \app to check whether our framework can correctly detect
these injected errors. \ennan{We also need a table here, 
and list each injected problem.}

Finally, we check suspicious values.

\subsection{Training Set Impact}

In this experiment, we vary the number of training configuration files,
and observe whether the correctness of \app would increase 
accordingly. \ennan{We may need a table whose x-axis is the number
of entries in the training configuration files, and y-axis is the 
accuracy or something close.}

\subsection{The Run-Time of Verification}

\ennan{Here, we need three pictures. In the first figure, x-axis should
be the number (or the size) of entries in the training dataset, and 
y-axis should be the run-time of parsing. In the second figure,
we need to measure the time of generating rules. }
